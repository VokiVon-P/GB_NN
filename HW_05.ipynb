{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Введение в искусственные нейронные сети\n",
    "# Урок 5. Рекуррентные нейронные сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HomeWork 05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте попробуем сделать простую реккурентную нейронную сеть, которая будет учиться складывать числа. Для этих целей мы не будем пользоваться фреймворками для Deep Learning, чтобы посмотреть как она работает внутри.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_stats(hist, score):\n",
    "    plt.plot(hist.history['accuracy'])\n",
    "    plt.plot(hist.history['val_accuracy'])\n",
    "    print(f\"Лучшее кол-во эпох: {np.argmax(hist.history['val_accuracy'])+1} \\\n",
    "          accuracy = {np.max(hist.history['val_accuracy'])}\")\n",
    "#     print(f\"Test accuracy: {score[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь давайте попробуем с помощью Keras построить LSTM нейронную сеть для оценки настроений отзвывов на IMD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данный датасет слишком мал, чтобы преимущества LSTM проявились, однако в учебных целях он подойдет.\n",
    "\n",
    "В тренировке рекуррентных нейронных сетей важную роль играет размер batch, но еще большую роль играет выбор функций loss и optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка данных...\n",
      "25000 тренировочные последовательности\n",
      "25000 тестовые последовательности\n",
      "Pad последовательности (примеров в x единицу времени)\n",
      "x_train shape: (25000, 100)\n",
      "x_test shape: (25000, 100)\n",
      "Построение модели...\n",
      "Процесс обучения...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\_ds_\\_env_\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/5\n",
      "25000/25000 [==============================] - 67s 3ms/step - loss: 0.5583 - accuracy: 0.7138 - val_loss: 0.3745 - val_accuracy: 0.8358\n",
      "Epoch 2/5\n",
      "25000/25000 [==============================] - 70s 3ms/step - loss: 0.3601 - accuracy: 0.8546 - val_loss: 0.3498 - val_accuracy: 0.8463\n",
      "Epoch 3/5\n",
      "25000/25000 [==============================] - 66s 3ms/step - loss: 0.2969 - accuracy: 0.8826 - val_loss: 0.3461 - val_accuracy: 0.8534\n",
      "Epoch 4/5\n",
      "25000/25000 [==============================] - 64s 3ms/step - loss: 0.2534 - accuracy: 0.9034 - val_loss: 0.3603 - val_accuracy: 0.8548\n",
      "Epoch 5/5\n",
      "25000/25000 [==============================] - 65s 3ms/step - loss: 0.2478 - accuracy: 0.9098 - val_loss: 0.3445 - val_accuracy: 0.8550\n",
      "25000/25000 [==============================] - 11s 429us/step\n",
      "Результат при тестировании: 0.34452616280317305\n",
      "Тестовая точность: 0.8550000190734863\n",
      "Wall time: 5min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from __future__ import print_function\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional\n",
    "from keras.layers import LSTM\n",
    "from keras.datasets import imdb\n",
    "from keras import optimizers\n",
    "\n",
    "\n",
    "max_features = 20000\n",
    "\n",
    "# обрезание текстов после данного количества слов (среди top max_features наиболее используемые слова)\n",
    "maxlen = 100\n",
    "batch_size = 100 # увеличьте значение для ускорения обучения\n",
    "num_epoch = 5\n",
    "\n",
    "print('Загрузка данных...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), 'тренировочные последовательности')\n",
    "print(len(x_test), 'тестовые последовательности')\n",
    "\n",
    "print('Pad последовательности (примеров в x единицу времени)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "print('Построение модели...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(256, dropout=0.3, recurrent_dropout=0.2, return_sequences=True))  \n",
    "model.add(LSTM(256, dropout=0.3, recurrent_dropout=0.2, return_sequences=True))  \n",
    "model.add(LSTM(256, dropout=0.3, recurrent_dropout=0.2))\n",
    "\n",
    "model.add(Dense(256, activation='relu', name='FC1'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# стоит попробовать использовать другие оптимайзер и другие конфигурации оптимайзеров \n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='RMSprop',\n",
    "#               optimizer=optimizers.Nadam(learning_rate=0.001),\n",
    "#               optimizer='adamax',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Процесс обучения...')\n",
    "hist = model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=num_epoch, # увеличьте при необходимости\n",
    "          validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Результат при тестировании:', score)\n",
    "print('Тестовая точность:', acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшее кол-во эпох: 5           accuracy = 0.8550000190734863\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3de3RV9Z338fc3V8iFQC5cQ7gG8FYQI9qqqFgFnbHU0nasnU7v1mfKTO3UC9NnrXnmma41Y622dkZba1vGzvRifYpW2lGBWitqrSUgyEUgISCEa0KAEALkcr7PH2cjh8OBnECSneR8XmtlnX35/fb57s3h993nt/f5bXN3REQk9aSFHYCIiIRDCUBEJEUpAYiIpCglABGRFKUEICKSojLCDqAziouLfezYsWGHISLSp6xcubLe3Uvil/epBDB27FgqKyvDDkNEpE8xs3cTLVcXkIhIilICEBFJUUoAIiIpSglARCRFKQGIiKQoJQARkRSlBCAikqL61O8ARET6s/aIc6C5hYYjLdQ3HWd/U3R6f9Nx5l1Wypii3C59PyUAEZFu4u40Hm2j/siJxvw49U0tJ6eDxj3ayLfQ0NxCoke0pBlcOmaIEoCISFjcnSMt7TQ0tSRs1PcfOR6cvZ9s2NsiiR+6VTAwk6K8LIpzsxlfnMflY7MoysumKDeLorwsinKzKc7LojA3i8E5WaSnWZfvjxKAiKS0Y63t7A/OxPcHZ+InGu/6mEZ9f1O0W+Z4WyThdvKyMygMGu9RgwcytbQgmD/ZkJ9o1IfkZpGZHv4lWCUAEelXWtsjHIhrvE+ckUfP0qPLT/SvNx1vS7id7Iw0ivOyKQoa7/Kh+Scb8mB5cW42hXlZFOVmMSAzvYf39PwpAYhIr9YecQ42t5w8Oz8S05DHXCg90SVz6Ghrwu1kpNkpZ+RlhTkU5QYNeV4WhbmnNuq5WemYdX23S2+iBCAiPa7xWCv1h4+f3qg3nbqs4Ui0cU/UjW4GhTlZ73W7XDBiEMW5MQ15XKM+aGBGv2/QO0sJQES63bHWdv68tYHlm+tYXlXH5r1NCcsNGpBBcV42hblZjCvOpWJsYdCox3S7BOuHdNOF0VSSVAIwsznAd4F04Efu/kDc+iHAQmACcAz4nLuvO1tdMysEfgmMBbYBH3f3A+e/SyISNnenel8Tr2yuY3lVPW/W7Od4W4Ss9DQuHzeEudNGMXLwgJgumGyG5GSRlRH+hdFU0mECMLN04DHgRqAWWGFmi919Q0yxrwOr3f02M5sSlL+hg7oLgJfc/QEzWxDM39+VOyciPedgcwuvVdezfHMdr1bVs/vQMQAmlORyxxVlzCwv4YrxheRkqeOht0jmX2IGUO3uNQBm9hQwF4hNABcC/wbg7hvNbKyZDQPGn6XuXOC6oP5PgD+gBCDSZ7S1R1i942DQrVPP27UHiTjkD8jg6onF/P0NJVxTXkzpkJywQ5UzSCYBjAJ2xMzXAlfElVkDfAR4zcxmAGOA0g7qDnP33QDuvtvMhiZ6czO7E7gToKysLIlwRaS71B5oZvnm6Fn+61vqOXysjTSDqaMH83ezypk5qYSppQVk9IJ73KVjySSARFdZ4q/JPwB818xWA2uBt4C2JOuelbs/ATwBUFFR0am6InJ+mlva+FPN/vca/Zr6IwCMKBjALRePYOakEq6aWMTgnKyQI5VzkUwCqAVGx8yXArtiC7h7I/BZAIveZ7U1+Ms5S929ZjYiOPsfAew7pz0QkS7j7mzY3cirVdEGv3LbAVraIwzITOOKcUV88soxXDupmAklebqlsh9IJgGsAMrNbBywE7gduCO2gJkNBprdvQX4ArDc3RvN7Gx1FwOfJvrt4dPAc12wPyLSSfVNx3ktaPCXV9VT33QcgCnD8/nMVWO5pryYy8cW9slfusrZdZgA3L3NzOYDS4jeyrnQ3deb2V3B+seBC4D/MrN2ohd4P3+2usGmHwCeNrPPA9uBj3XtrolIIi1tEVa+e4DlVXW8WlXHup2NAAzJyeTq8hJmlhczc1IJwwYNCDlS6W7micYe7aUqKiq8srIy7DBE+pxt9UdYXlXH8s11vLFlP0da2slIM6aXDWHmpGKuKS/h4lEF+mFVP2VmK929In65bsgV6YcOH2vlj1v2v3dP/vaGZgBGFw7kw5eOYuakEj4woYj8AZkhRyphUgIQ6QciEWftzkPvNfirth+gLeLkZKXzgQlFfOGaccwsL2FMUY4u3sp7lABE+qi9jcfeu3D7WlUdB5qjo2BePGoQd84czzXlJVw2ZoiGV5AzUgIQ6SOOtbazYlvDe2f5G/ccBqA4L5vrJw9l5qQSri4vpjgvO+RIpa9QAhDppdydLXVNvBL8COvNrfs51hodUK1i7BAW3DyFa8qLuWD4INJ08VbOgRKASC9yqLk1ZkC1OnYFA6qNL87l9svLmDmpmCvHF2lANekS+hSJhKitPcKa2oO8srmeV6vqWLPj5IBqV00oZv6s6IBqows1oJp0PSUAkR628+DR6MXbzXW8Xl1P47E2zGBq6WDmzypnZnkx00YP1oBq0u2UAES6WXNLG2/WNPBK0K2zpS46oNrwQQOYc/Hw6MXbicUaUE16nBKASBdzd97ZfZhXq6KPP1yxNTqgWnZGGleML+ITM8qYOamE8qEaUE3CpQQg0gX2Nx3nter64Cy/nrrD0QHVJg3L42/eP4aZk0qYMU4DqknvogQgco6OHG/jxXV7WLSqljdq9uMOg3MyuXpidDC1meUlDC/QgGrSeykBiHRCJOL8qWY/v1pVy4vr9tDc0k5ZYQ5/N6ucWVOGcokGVJM+RAlAJAlb64+waGUtz761k50Hj5KfncGHpo5k3mWlVIwZor586ZOUAETO4NDRVn779i4Wraxl1faDpBlcXV7CfXMmc9OFwxmYpf586duUAERitLVHeLWqnl+tqmXZhr20tEWYODSPBTdP4cPTRqlPX/qVpBKAmc0Bvkv0qV4/cvcH4tYXAD8FyoJtPuTu/2lmk4FfxhQdD/yTuz9iZv8MfBGoC9Z93d2fP5+dETlXG/c0smhlLb9evYu6w8cZnJPJ7ZePZt70Ut5XWqAuHumXOkwAZpYOPAbcSPQB8SvMbLG7b4gp9mVgg7vfamYlwCYz+5m7bwKmxWxnJ/BsTL3vuPtDXbQvIp2yv+k4i9fsYtGqWtbtbCQjzbhu8lA+etkorp8ylOwMdfFI/5bMN4AZQLW71wCY2VPAXKLP/j3BgXyLniblAQ1AW9x2bgC2uPu75x21yDlqaYvw+437WLSqlpc37qMt4lw0chD/9JcXMnfaSIo0lLKkkGQSwChgR8x8LXBFXJlHgcXALiAf+Ct3j8SVuR34Rdyy+Wb2N0Al8DV3PxD/5mZ2J3AnQFlZWRLhipzK3Xm79hCLVtWyeM0uDja3UpKfzeeuHsdHpo9iyvBBYYcoEopkEkCizs/4J8nPBlYDs4AJwDIze9XdGwHMLAv4EPCPMXW+D3wj2NY3gIeBz532Ru5PAE9A9KHwScQrAsCeQ8d49q2dPLOqlqp9TWRlpHHThcOYd1kp10ws1mBrkvKSSQC1wOiY+VKiZ/qxPgs84O4OVJvZVmAK8Odg/c3AKnffe6JC7LSZ/RD4befDFznV0ZZ2lm7Yw69W1vJ6dT0Rh8vGDOFfb7uEv3jfCAoG6iHoIickkwBWAOVmNo7oRdzbgTviymwn2sf/qpkNAyYDNTHrP0Fc94+ZjXD33cHsbcC6zocvEu3iWbHtAItW1vL82t0cPt7GqMED+fL1E/nI9FLGFeeGHaJIr9RhAnD3NjObDywhehvoQndfb2Z3BesfJ9qF86SZrSXaZXS/u9cDmFkO0TuIvhS36QfNbBrRLqBtCdaLnNWOhmYWrarlmVU72d7QTE5WOjdfPIJ5l43iynFFekyiSAcs2mvTN1RUVHhlZWXYYUiImo638fza3SxaWcubWxswg/ePL2Le9FLmXDyc3Gz9tlEknpmtdPeK+OX63yK9XnvE+eOWep5ZtZMX1+3haGs744pzueemSdw2vZRRgweGHaJIn6QEIL1W9b4mFq2q5ddv7WT3oWPkD8jgtumjmDe9lOllg/XrXJHzpAQgvcrB5hZ+s2YXv1q1kzU7DpKeZswsL+Z//8UFfPCCYXqgikgXUgKQ0LW2R3hlUx2LVtXy0jv7aGmPMGV4Pv/7lguYe+lIhuZrADaR7qAEIKFZv+sQi1buZPGandQ3tVCYm8Unryxj3vRSLho5SF08It1MCUB6VN3h4zy3eie/WlnLxj2HyUw3bpgS/XXudZNLyNSvc0V6jBKAdLtjre289E50ALZXNtfRHnGmlhbwL3Mv4tb3jWRIblbYIYqkJCUA6Rbuzls7DrJoZS2/fXs3h462MmxQNl+8Zjzzpo+ifFh+2CGKpDwlAOlSuw4e5dm3drJoVS01dUcYkJnG7IuGM296KVdNLNYD00V6ESUAOW/NLW28uG4Pi1bV8sct+3GHGWML+dLM8dxyyQjyB2gANpHeSAlAzkkk4ry5tYFFq2p5Ye1ujrS0M7pwIH8/q5x500spK8oJO0QR6YASgHTKtvojPLOqlmfe2kntgaPkZWfwF+8bwbzppVw+tlADsIn0IUoA0qHGY638z9vRAdgq3z2AGVw9sZh7bprM7IuGMzBLv84V6YuUACSh9ojzalUdi1btZOn6PRxvizChJJf75kzmtktHMaJAA7DJeYhE4L2nxjq8NypxV02TYLnHLO+qaTpft9P7FEwWTYCBg+lKSgBymj9W1/PVp1ezt/E4BQMz+XjFaOZdVsrU0gL9OjcM7hBpg/ZWiLRCe1vw2hpdfsZ1J+bjyp/3ds60vVaItJ/9vU4sO+2pstKhTy6C8g926SaVAOQUre0Rvv7sWgZkpvP9T05n1gVDyc5QF8972lvhSB007YWmfcHrXmhugPaWJBrTmOWRtrM0pjENZqSt5/bP0iAtE9IzIS0jeD0xnZF4XUYWpOWeXB67LmGdoIyl8d4jx42YaeumaU5d/t6y7pimgzLnsB8jp9HVkkoAZjYH+C7RJ4L9yN0fiFtfAPwUKAu2+ZC7/2ewbhtwGGgH2k48lMDMCoFfAmOJPhHs4+5+4Lz3SM7LUyt2sG1/Mz/+dAU3XDAs7HB6hjscPXCyMY9t2N+bDl6b9yfeRlZeTKOXeZZGMBMyB0L6oMTrTsyf1uAmaEw7bGg7aLgTbSdNQ3Gkkg4TgJmlA48RfaxjLbDCzBa7+4aYYl8GNrj7rWZWAmwys5+5e0uw/voTj4iMsQB4yd0fMLMFwfz957tDcu6aW9r495equHzsEGZNGRp2OOev5UjiRvy0ZfuiZ9vx0rMhfxjkDYPC8VB2ZXQ6b2jwGkznDoVMjVgqfU8y3wBmANXuXgNgZk8Bc4HYBOBAvkU7iPOABqCj761zgeuC6Z8Af0AJIFQLX9tK3eHjPP7X03tvX/+ZumBOa+T3QUvT6fUtDXJLTjbiQy+MadDjGvbsQad+pRfpZ5JJAKOAHTHztcAVcWUeBRYDu4B84K/cYy/xs9TMHPiBuz8RLB/m7rsB3H23mfWDU86+q+FICz94pYYbLxzGZWMKe/bNu6ILZkDBycZ75KVxDXpMw55TBGm6piECySWARKdA8ZfwZwOrgVnABGCZmb3q7o3AVe6+K2jgl5nZRndfnmyAZnYncCdAWVlZstWkkx57uZojLW3cN3ty121UXTAivVoyCaAWGB0zX0r0TD/WZ4EH3N2BajPbCkwB/uzuuwDcfZ+ZPUu0S2k5sNfMRgRn/yOAfYnePPjG8ARARUWF7h3rBrUHmvnvN95l3vTSjkfpbG+FI/XQtEddMCJ9XDIJYAVQbmbjgJ3A7cAdcWW2AzcAr5rZMGAyUGNmuUCaux8Opm8C/iWosxj4NPBA8Prc+e6MnJvvLKsCg3+4diTsfhsObIWDO87SBZMgD2cXnGzAR0yLvuYPUxeMSC/WYQJw9zYzmw8sIXob6EJ3X29mdwXrHwe+ATxpZmuJdhnd7+71ZjYeeDa4oJgB/NzdXww2/QDwtJl9nmgC+VgX75vEc4/er95QE23kG2o4tGszn9i4ln8ZUEfu9+Luwk3PPtmADxkLo2ckPlPPGxq9tVFE+hRz7zu9KhUVFV5ZWRl2GL1bJAKHd5/SyNOwNZjeCscbTynekF5CdftQpl4yjeyhE6J97UPGwZAxMGCwumBE+gEzW3niN1ix9Evgvqi9FQ5uj2nYYxr5A9ug7djJsmkZMLgs2rCXzoi+Fo6DIeOobBzER3/0FvfOnsyM6yeGtjsiEg4lgN6qpTnamMefyTfUwKFa8PaTZTMGRhv1ookw8YOnNPIUjI7+EjSOu/Nvi95gaH42n7tqXM/tl4j0GkoAYTp64PQumhONfNOeU8sOGBxt1Esr4JKPndrI5w/vdFfN797Zx8p3D/Cvt12i4ZxFUpQSQHdyj945c0ojH3Mmf+zgqeXzhkcb9ok3RBv2wnEnG/mcrvtxVnvEefDFjYwvzuXjFaVdtl0R6VuUAM5Xexs01iY+kz+wFVqbT5a1tGiXTOF4uPgjQSN/4kx+LGTl9kjIi1bVUrWvie99cjoZ6Rr8SyRVKQEko/UYHHw38Zn8wXdPHa43PTvamBeOh/HXntrIF4yODp0bomOt7TyybDNTSwu4+eLhocYiIuFSAjjhWOPpXTQHtkWnG3dyyo+fsgdFG/nhl8CFHzq1kc8f2auH1P3vN95l16FjPPTxqb13wDcR6RGpkwDco0MYnNbIB6/xg4zllkQb9rFXn+yHP9HI5xT1yfvjDx1t5dGXq5k5qYQPTCgOOxwRCVlqJICX/gXefAJaDscsNCgojZ7JT/nL0xv57A7GxOmDfvDKFg4dbe3aAd9EpM9KjQRQMgWm3RHcVRP80nVwWUqNILm38RgLX9/Kh6aO5OJRBWGHIyK9QGokgPd9PPqXwr77UhXtEeeem3T2LyJRvfdqpXSZLXVN/HLFDu6YUUZZUU7Y4YhIL6EEkAIeXrqJ7Iw05s8qDzsUEelFlAD6uTU7DvL82j184ZrxlORnhx2OiPQiSgD9mLvzwAsbKcrN4ovXaMA3ETmVEkA/tryqnjdq9jN/1kTyB2SGHY6I9DJKAP1UJOJ884WNlA4ZyB1XlIUdjoj0QkklADObY2abzKzazBYkWF9gZr8xszVmtt7MPhssH21mL5vZO8Hyr8TU+Wcz22lmq4O/W7put+Q3b+9iw+5GvnbTJLIzNNyziJyuw98BmFk68BhwI1ALrDCzxe6+IabYl4EN7n6rmZUAm8zsZ0Ab8DV3X2Vm+cBKM1sWU/c77v5Ql+6R0NIW4eGlm5kyPJ+5U0eFHY6I9FLJfAOYAVS7e427twBPAXPjyjiQb9HRxfKABqDN3Xe7+yoAdz8MvAOoRepmT63YzvaGZu6/eQppaX1vzCIR6RnJJIBRwI6Y+VpOb8QfBS4AdgFrga+4eyS2gJmNBS4F3oxZPN/M3jazhWY2JNGbm9mdZlZpZpV1dXVJhJvajhxv499fquKKcYVcN6kk7HBEpBdLJgEkOoX0uPnZwGpgJDANeNTMBr23AbM8YBFwt7s3Bou/D0wIyu8GHk705u7+hLtXuHtFSYkatI786NWt1De1cP/NUzTcs4icVTIJoBYYHTNfSvRMP9ZngWc8qhrYCkwBMLNMoo3/z9z9mRMV3H2vu7cH3xR+SLSrSc7D/qbjPLF8C7MvGsb0soRfqERE3pNMAlgBlJvZODPLAm4HFseV2Q7cAGBmw4DJQE1wTeDHwDvu/u3YCmY2Imb2NmDdue2CnPDoy9UcbW3n3tlTwg5FRPqADu8Ccvc2M5sPLAHSgYXuvt7M7grWPw58A3jSzNYS7TK6393rzexq4FPAWjNbHWzy6+7+PPCgmU0j2p20DfhSF+9bStnR0MxP//QuH68YzcSheWGHIyJ9QFLDQQcN9vNxyx6Pmd4F3JSg3mskvoaAu3+qU5HKWX172WbSzLj7g5PCDkVE+gj9ErgfeGd3I79evZPPXDWW4QWp85AbETk/SgD9wIMvbiQ/O4O/vXZi2KGISB+iBNDH/almPy9vquNvr59IQY4GfBOR5CkB9GEnhnsePmgAn/nA2LDDEZE+RgmgD1uyfi+rdxzk7g+WMyBTA76JSOcoAfRRbe0RvrVkIxNKcvnoZaVhhyMifZASQB/1q5W1bKk7wr2zp5CRrn9GEek8tRx90LHWdh75XRWXlg1m9kXDwg5HRPooJYA+6Mk/bmNP4zHun6MB30Tk3CkB9DGHmlv53svVXD+5hCvHF4Udjoj0YUoAfcz3Xqnm8PE27pujAd9E5PwoAfQhuw8d5cnXt/HhaaO4YMSgjiuIiJyFEkAf8t3fVRFx5x9u1IBvInL+lAD6iOp9TTxduYNPXjGG0YU5YYcjIv2AEkAf8a0lG8nJyuDvZmnANxHpGkoAfcCq7QdYsn4vX7xmPEV52WGHIyL9RFIJwMzmmNkmM6s2swUJ1heY2W/MbI2ZrTezz3ZU18wKzWyZmVUFr3qIbQLuzjdf2EhxXhZfuGZc2OGISD/SYQIws3TgMeBm4ELgE2Z2YVyxLwMb3H0qcB3wsJlldVB3AfCSu5cDLwXzEucPm+t4c2sDfzernNzspB7gJiKSlGS+AcwAqt29xt1bgKeAuXFlHMgPHgKfBzQAbR3UnQv8JJj+CfDh89qTfigSiZ79lxXm8IkZZWGHIyL9TDIJYBSwI2a+NlgW61HgAmAXsBb4irtHOqg7zN13AwSvQxO9uZndaWaVZlZZV1eXRLj9x3NrdrJxz2G+dtMksjJ0uUZEulYyrUqiwWY8bn42sBoYCUwDHjWzQUnWPSt3f8LdK9y9oqSkpDNV+7Tjbe08vHQzF40cxK3vGxl2OCLSDyWTAGqB0THzpUTP9GN9FnjGo6qBrcCUDuruNbMRAMHrvs6H33/9/M3t1B44yn1zppCWpgHfRKTrJZMAVgDlZjbOzLKA24HFcWW2AzcAmNkwYDJQ00HdxcCng+lPA8+dz470J4ePtfIfv6/mAxOKmFleHHY4ItJPdXhbibu3mdl8YAmQDix09/Vmdlew/nHgG8CTZraWaLfP/e5eD5CobrDpB4CnzezzRBPIx7p21/quH766lYYjLRruWUS6VVL3Fbr788Dzccsej5neBdyUbN1g+X6Cbw1yUt3h4/zo1RpuuWQ4U0cPDjscEenHdGtJL/Po76s43hbhnpsmhx2KiPRzSgC9yLv7j/DzP2/nry4fzfiSvLDDEZF+TgmgF3l46WbS04yv3FAedigikgKUAHqJdTsPsXjNLj531TiGDRoQdjgikgKUAHqJB5dsomBgJl+6dkLYoYhIilAC6AX+WF3P8s11zL9+IgUDM8MOR0RShBJAyNydb764kZEFA/jU+8eEHY6IpBAlgJC9sG4Pa2oPcfeNkxiQmR52OCKSQpQAQtTWHuGhJZsoH5rHvOmlYYcjIilGCSBET1fWUlN/hHtnTyZdA76JSA9TAgjJ0ZZ2HvndZi4bM4QbLxwWdjgikoKUAEKy8PWt7Dt8nAU3a8A3EQmHEkAIDja38PgrW7hhylAuH1sYdjgikqKUAELwvT9soel4G/fO0YBvIhIeJYAetvPgUZ784zY+cmkpU4YPCjscEUlhSgA97JFlm8HhqzdqwDcRCVdSCcDM5pjZJjOrNrMFCdbfa2arg791ZtZuZoVmNjlm+WozazSzu4M6/2xmO2PW3dLVO9fbVO09zKJVtXzq/WMoHZITdjgikuI6fCKYmaUDjwE3En3I+wozW+zuG06UcfdvAd8Kyt8KfNXdG4AGYFrMdnYCz8Zs/jvu/lAX7Uuv9+CSTeRmZfDl6yeGHYqISFLfAGYA1e5e4+4twFPA3LOU/wTwiwTLbwC2uPu7nQ+z76vc1sCyDXv50rXjKczNCjscEZGkEsAoYEfMfG2w7DRmlgPMARYlWH07pyeG+Wb2tpktNLMhZ9jmnWZWaWaVdXV1SYTb+5wY8K0kP5vPXT0u7HBERIDkEkCiXyn5GcreCrwedP+c3IBZFvAh4P/FLP4+MIFoF9Fu4OFEG3T3J9y9wt0rSkpKkgi39/n9xn2s2HaAv7+hnJysDnvdRER6RDIJoBYYHTNfCuw6Q9lEZ/kANwOr3H3viQXuvtfd2909AvyQaFdTv9MecR58cRNji3K4/fLRHVcQEekhySSAFUC5mY0LzuRvBxbHFzKzAuBa4LkE2zjtuoCZjYiZvQ1Yl2zQfcmzb+1k097D3DN7MpnpuutWRHqPDvsj3L3NzOYDS4B0YKG7rzezu4L1jwdFbwOWuvuR2PrBdYEbgS/FbfpBM5tGtDtpW4L1fd6x1na+s2wzl4wq4JaLR3RcQUSkByXVIe3uzwPPxy17PG7+SeDJBHWbgaIEyz/ViTj7pJ/+6V12HjzKN+e9jzQN9ywivYz6JLpJ47FWHnu5mqsnFnN1eXHY4YiInEYJoJs88UoNB5pbuX/OlLBDERFJSAmgG+xrPMaPX9vKX75vBJeUFoQdjohIQkoA3eDff19Fa3uEe27ScM8i0nspAXSxrfVHeOrPO7h9xmjGFueGHY6IyBkpAXSxh5ZuIjM9jb+/QcM9i0jvpgTQhdbWHuJ/3t7NF64Zx9D8AWGHIyJyVkoAXeibL25kSE4md84cH3YoIiIdUgLoIq9W1fFadT1fvn4i+QMyww5HRKRDSgBdIBKJDvc8avBA/vrKMWGHIyKSFCWALvA/a3ezbmcj/3DjJAZkpocdjohIUpQAzlNre4SHl25i8rB8PnxpwufkiIj0SkoA5+mpFTvYtr+Z++ZMJl0DvolIH6IEcB6OHG/ju7+r4vKxQ5g1ZWjY4YiIdIoSwHlY+NpW6puOs+DmKZjp7F9E+hYlgHPUcKSFHyyv4cYLh3HZmMKwwxER6bSkEoCZzTGzTWZWbWYLEqy/18xWB3/rzKzdzAqDddvMbG2wrjKmTqGZLTOzquB1SNftVvd77OVqmlvauG+2BnwTkb6pwwRgZunAY0Qf7H4h8AkzuzC2jLt/y92nufs04B+BV9y9IabI9cH6iphlC4CX3L0ceCmY7xNqDzTz32+8y7zppRO/6c4AAApJSURBVJQPyw87HBGRc5LMN4AZQLW717h7C/AUMPcs5U97APwZzAV+Ekz/BPhwEnV6hW8v2wwGX71xUtihiIics2QSwChgR8x8bbDsNMED4OcAi2IWO7DUzFaa2Z0xy4e5+26A4DXhbTRmdqeZVZpZZV1dXRLhdq+Nexp59q2dfOYDYxk5eGDY4YiInLNkEkCi21v8DGVvBV6P6/65yt2nE+1C+rKZzexMgO7+hLtXuHtFSUlJZ6p2i2+9uIm87Az+9roJYYciInJekkkAtcDomPlSYNcZyt5OXPePu+8KXvcBzxLtUgLYa2YjAILXfcmHHY4/b23gpY37uOvaCQzOyQo7HBGR85JMAlgBlJvZODPLItrIL44vZGYFwLXAczHLcs0s/8Q0cBOwLli9GPh0MP3p2Hq9kbvzwAvvMDQ/m89dNS7scEREzltGRwXcvc3M5gNLgHRgobuvN7O7gvWPB0VvA5a6+5GY6sOAZ4MfSWUAP3f3F4N1DwBPm9nnge3Ax7pih7rLsg17WbX9IP962yUMzNKAbyLS95n7mbrze5+KigqvrKzsuGAXa484cx5ZTnvEWfrVmWSk6/dzItJ3mNnKuNvwAf0SOCmLVtVSta+Je2ZPVuMvIv2GWrMOHGtt5zvLNjO1tICbLx4edjgiIl1GCaAD//XGNnYfOsb9GvBNRPoZJYCzOHS0lcde3sLMSSV8YEJx2OGIiHQpJYCz+MErWzh0tFUDvolIv6QEcAZ7G4+x8PWtfGjqSC4eVRB2OCIiXU4J4Awe+V0V7RHnnpt09i8i/ZMSQAJb6pp4unIHd8woo6woJ+xwRES6hRJAAg8v3UR2RhrzZ5WHHYqISLdRAoizesdBnl+7hy9cM56S/OywwxER6TZKADHcnW++sJGi3Cy+eI0GfBOR/k0JIMbyqnreqNnP/FkTyR+QGXY4IiLdSgkgEIlEz/5LhwzkjivKwg5HRKTbKQEEfvP2LjbsbuRrN00iO0PDPYtI/6cEALS0RXh46WYuGDGIuVMTPu5YRKTfUQIAfvHn7WxvaOa+OZNJS9OAbyKSGpJKAGY2x8w2mVm1mS1IsP5eM1sd/K0zs3YzKzSz0Wb2spm9Y2brzewrMXX+2cx2xtS7pSt3LFlNx9v4j99XccW4Qq6bFP5D50VEekqHj4Q0s3TgMeBGog+IX2Fmi919w4ky7v4t4FtB+VuBr7p7g5llA19z91XBs4FXmtmymLrfcfeHunifOuVHr9ZQ39TCE3+j4Z5FJLUk8w1gBlDt7jXu3gI8Bcw9S/lPAL8AcPfd7r4qmD4MvAP0mk72+qbj/HB5DXMuGs70siFhhyMi0qOSSQCjgB0x87WcoRE3sxxgDrAowbqxwKXAmzGL55vZ22a20Mx6vAV+9PfVHG1t5x4N9ywiKSiZBJCoX+RMT5K/FXjd3RtO2YBZHtGkcLe7NwaLvw9MAKYBu4GHE7652Z1mVmlmlXV1dUmEm5wdDc387M13+XjFaCYOzeuy7YqI9BXJJIBaYHTMfCmw6wxlbyfo/jnBzDKJNv4/c/dnTix3973u3u7uEeCHRLuaTuPuT7h7hbtXlJR03UXah5duIs2Muz84qcu2KSLSlySTAFYA5WY2zsyyiDbyi+MLmVkBcC3wXMwyA34MvOPu344rPyJm9jZgXefDPzcbdjXy3JpdfOaqsQwvGNBTbysi0qt0eBeQu7eZ2XxgCZAOLHT39WZ2V7D+8aDobcBSdz8SU/0q4FPAWjNbHSz7urs/DzxoZtOIdidtA77UFTuUjAeXbCQ/O4O/vXZiT72liEiv02ECAAga7Ofjlj0eN/8k8GTcstdIfA0Bd/9UJ+LsMn+q2c8fNtWx4OYpFORowDcRSV0p9Utgd+eBFzYyfNAAPvOBsWGHIyISqpRKAEvW72H1joPc/cFyBmRqwDcRSW0pkwDa2iM8uGQTE0py+ehlpWGHIyISupRJAL9aWUtN3RHunT2FjPSU2W0RkTNKiZbwaEs7j/yuikvLBjP7omFhhyMi0iukRAJ48o/b2NN4jPvnaMA3EZETUiIBlORn87HLSrlyfFHYoYiI9BpJ/Q6gr/voZaW68CsiEiclvgGIiMjplABERFKUEoCISIpSAhARSVFKACIiKUoJQEQkRSkBiIikKCUAEZEUZe5ner5772NmdcC751i9GKjvwnC6iuLqHMXVOYqrc3prXHB+sY1x99Meqt6nEsD5MLNKd68IO454iqtzFFfnKK7O6a1xQffEpi4gEZEUpQQgIpKiUikBPBF2AGeguDpHcXWO4uqc3hoXdENsKXMNQERETpVK3wBERCSGEoCISIrqdwnAzOaY2SYzqzazBQnWm5n9e7D+bTOb3kvius7MDpnZ6uDvn3ogpoVmts/M1p1hfVjHqqO4evxYBe872sxeNrN3zGy9mX0lQZkeP2ZJxhXG52uAmf3ZzNYEcf3fBGXCOF7JxBXKZyx473Qze8vMfptgXdceL3fvN39AOrAFGA9kAWuAC+PK3AK8ABhwJfBmL4nrOuC3PXy8ZgLTgXVnWN/jxyrJuHr8WAXvOwKYHkznA5t7yecrmbjC+HwZkBdMZwJvAlf2guOVTFyhfMaC9/4H4OeJ3r+rj1d/+wYwA6h29xp3bwGeAubGlZkL/JdH/QkYbGYjekFcPc7dlwMNZykSxrFKJq5QuPtud18VTB8G3gFGxRXr8WOWZFw9LjgGTcFsZvAXf9dJGMcrmbhCYWalwF8APzpDkS49Xv0tAYwCdsTM13L6f4RkyoQRF8D7g6+lL5jZRd0cUzLCOFbJCvVYmdlY4FKiZ4+xQj1mZ4kLQjhmQXfGamAfsMzde8XxSiIuCOcz9ghwHxA5w/ouPV79LQFYgmXxmT2ZMl0tmfdcRXS8jqnAfwC/7uaYkhHGsUpGqMfKzPKARcDd7t4YvzpBlR45Zh3EFcoxc/d2d58GlAIzzOziuCKhHK8k4urx42Vmfwnsc/eVZyuWYNk5H6/+lgBqgdEx86XArnMo0+NxuXvjia+l7v48kGlmxd0cV0fCOFYdCvNYmVkm0Ub2Z+7+TIIioRyzjuIK+/Pl7geBPwBz4laF+hk7U1whHa+rgA+Z2Tai3cSzzOyncWW69Hj1twSwAig3s3FmlgXcDiyOK7MY+JvgavqVwCF33x12XGY23MwsmJ5B9N9mfzfH1ZEwjlWHwjpWwXv+GHjH3b99hmI9fsySiSuMY2ZmJWY2OJgeCHwQ2BhXLIzj1WFcYRwvd/9Hdy9197FE24jfu/tfxxXr0uOVce7h9j7u3mZm84ElRO+8Weju683srmD948DzRK+kVwPNwGd7SVwfBf6XmbUBR4HbPbjs313M7BdE73YoNrNa4P8QvSAW2rFKMq4eP1aBq4BPAWuD/mOArwNlMbGFccySiSuMYzYC+ImZpRNtQJ9299+G/f8xybjC+oydpjuPl4aCEBFJUf2tC0hERJKkBCAikqKUAEREUpQSgIhIilICEBFJUUoAIiIpSglARCRF/X+x/bojO0XBtAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_stats(hist, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Мои наблюдения по LSTM\n",
    "\n",
    "<ol>\n",
    "    <li>Увеличение maxlen до 100 помогло увеличить точность</li>\n",
    "    <li>Размер батча повел себя интересно: при простых сетях уменьшение батча увеличивало качество, при усложнении сети батч меньше 100 приводил к ухудшению</li>\n",
    "    <li>Оптимизатор и его параметры не особенно сказались на точности системы (перебрал adam, adamax, RMSprop, Nadam </li>\n",
    "    <li>Добавление стекинга с дополнительными LTSM слоями стабилизировали результаты и немного увеличил точность</li>\n",
    "    <li>Добавление дополнительной комбинации денс слоя с дропаутом позволили обучаться дальше 1 эпохи и также повысили точность </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Часть 2 - генератор GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте также посмотрим пример в котором будет использоваться другой класс задач - генерация текста на основе тренировочного текста. В задачу нейросети будет входить обучившись на тексте Алиса в стране чудес и начать генерировать текст похожий на тот, что можно встретить в этой книге. Также в этом примере будет использоваться GRU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Итерация #: 0\n",
      "Epoch 1/1\n",
      "752033/752033 [==============================] - 51s 68us/step - loss: 2.2230\n",
      "Генерация из посева: а лестнице\n",
      "а лестнице под столоную под столоную под столоную под столоную под столоную под столоную под столоную под стол==================================================\n",
      "Итерация #: 1\n",
      "Epoch 1/1\n",
      "752033/752033 [==============================] - 48s 64us/step - loss: 1.8080\n",
      "Генерация из посева: вас об это\n",
      "вас об этом прокуратор по стене прокуратор по стене прокуратор по стене прокуратор по стене прокуратор по стен==================================================\n",
      "Итерация #: 2\n",
      "Epoch 1/1\n",
      "752033/752033 [==============================] - 49s 65us/step - loss: 1.6837\n",
      "Генерация из посева:  Как ваша \n",
      " Как ваша на своем столба в комнате в комнате в комнате в комнате в комнате в комнате в комнате в комнате в ко==================================================\n",
      "Итерация #: 3\n",
      "Epoch 1/1\n",
      "752033/752033 [==============================] - 49s 65us/step - loss: 1.6193\n",
      "Генерация из посева: ет в ледян\n",
      "ет в ледяние на столе под ним на столе под ним на столе под ним на столе под ним на столе под ним на столе под==================================================\n",
      "Итерация #: 4\n",
      "Epoch 1/1\n",
      "752033/752033 [==============================] - 51s 68us/step - loss: 1.5792\n",
      "Генерация из посева: у, что вас\n",
      "у, что вас поднялся в столбах и поднимая с под стены и поднялся в столбах и поднимая с под стены и поднялся в ==================================================\n",
      "Итерация #: 5\n",
      "Epoch 1/1\n",
      "752033/752033 [==============================] - 49s 65us/step - loss: 1.5512\n",
      "Генерация из посева: сь над Ерш\n",
      "сь над Ершалаиме с полу собою в столовку и поднялся в столовку и поднялся в столовку и поднялся в столовку и п==================================================\n",
      "Итерация #: 6\n",
      "Epoch 1/1\n",
      "752033/752033 [==============================] - 52s 69us/step - loss: 1.5289\n",
      "Генерация из посева: ко что про\n",
      "ко что прокуратор, – ответил Иван, – ответил Иван, – ответил Иван, – ответил Иван, – ответил Иван, – ответил И==================================================\n",
      "Итерация #: 7\n",
      "Epoch 1/1\n",
      "752033/752033 [==============================] - 54s 72us/step - loss: 1.5126\n",
      "Генерация из посева: ожет быть \n",
      "ожет быть не понять в кабинете и поднялась на своей столба и поднялась на своей столба и поднялась на своей ст==================================================\n",
      "Итерация #: 8\n",
      "Epoch 1/1\n",
      "752033/752033 [==============================] - 52s 69us/step - loss: 1.4992\n",
      "Генерация из посева: а». – Ага.\n",
      "а». – Ага... – Ну, что же вы сказал: – Вот он под столом и поднялся в комнату и поднялся в комнату и поднялся ==================================================\n",
      "Итерация #: 9\n",
      "Epoch 1/1\n",
      "752033/752033 [==============================] - 50s 67us/step - loss: 1.4878 0s -\n",
      "Генерация из посева: рита покре\n",
      "рита покрепите в сторону и поднялся в сторону и поднялся в сторону и поднялся в сторону и поднялся в сторону и==================================================\n",
      "Итерация #: 10\n",
      "Epoch 1/1\n",
      "752033/752033 [==============================] - 51s 67us/step - loss: 1.4780\n",
      "Генерация из посева: и глазами \n",
      "и глазами и поднялся в каких-то подошла в кабинете и поднялся в каких-то подошла в кабинете и поднялся в каких==================================================\n",
      "Итерация #: 11\n",
      "Epoch 1/1\n",
      "752033/752033 [==============================] - 54s 72us/step - loss: 1.4693\n",
      "Генерация из посева: далилась, \n",
      "далилась, что он поднялся в комнате в кабинете и поднялся в комнате в кабинете и поднялся в комнате в кабинете==================================================\n",
      "Итерация #: 12\n",
      "Epoch 1/1\n",
      "752033/752033 [==============================] - 52s 69us/step - loss: 1.4621 1\n",
      "Генерация из посева: слова. – Н\n",
      "слова. – Не пришел в какой-то не пришел в какой-то не пришел в какой-то не пришел в какой-то не пришел в какой==================================================\n",
      "Итерация #: 13\n",
      "Epoch 1/1\n",
      "752033/752033 [==============================] - 51s 68us/step - loss: 1.4562\n",
      "Генерация из посева: а перед пр\n",
      "а перед прокуратора под ним под нею и подумал Коровьев, – просто под нею и подумал Коровьев, – просто под нею ==================================================\n",
      "Итерация #: 14\n",
      "Epoch 1/1\n",
      "752033/752033 [==============================] - 50s 66us/step - loss: 1.4504\n",
      "Генерация из посева: ь сильно х\n",
      "ь сильно хорошо под ним под ним под ним под ним под ним под ним под ним под ним под ним под ним под ним под ни==================================================\n",
      "Итерация #: 15\n",
      "Epoch 1/1\n",
      "752033/752033 [==============================] - 50s 67us/step - loss: 1.4458\n",
      "Генерация из посева: ни. И вот \n",
      "ни. И вот в каком-то страшный под столиками и поднялся в сторону и поднялся в сторону и поднялся в сторону и п==================================================\n",
      "Итерация #: 16\n",
      "Epoch 1/1\n",
      "752033/752033 [==============================] - 54s 72us/step - loss: 1.4394\n",
      "Генерация из посева: ир, – отоз\n",
      "ир, – отозвался по своей подвал и поднялся в комнату и поднялся в комнату и поднялся в комнату и поднялся в ко==================================================\n",
      "Итерация #: 17\n",
      "Epoch 1/1\n",
      "752033/752033 [==============================] - 54s 72us/step - loss: 1.4367\n",
      "Генерация из посева: ова: «Умол\n",
      "ова: «Умоляю, и в том, что он поднял по своей подворотне, и в том, что он поднял по своей подворотне, и в том,==================================================\n",
      "Итерация #: 18\n",
      "Epoch 1/1\n",
      "752033/752033 [==============================] - 51s 68us/step - loss: 1.4310\n",
      "Генерация из посева: ак будто ж\n",
      "ак будто же вы не поднялся в сторону и поднялся в сторону и поднялся в сторону и поднялся в сторону и поднялся==================================================\n",
      "Итерация #: 19\n",
      "Epoch 1/1\n",
      "752033/752033 [==============================] - 52s 69us/step - loss: 1.4268\n",
      "Генерация из посева: .. спокойн\n",
      ".. спокойно ответил Воланд, – ответил Воланд, – ответил Воланд, – ответил Воланд, – ответил Воланд, – ответил ==================================================\n",
      "Итерация #: 20\n",
      "Epoch 1/1\n",
      "752033/752033 [==============================] - 48s 64us/step - loss: 1.4242\n",
      "Генерация из посева: спросил Ив\n",
      "спросил Иван, – ответил Воланд, – ответил Воланд, – ответил Воланд, – ответил Воланд, – ответил Воланд, – отве==================================================\n",
      "Итерация #: 21\n",
      "Epoch 1/1\n",
      "752033/752033 [==============================] - 51s 68us/step - loss: 1.4205 0s - loss: 1.\n",
      "Генерация из посева: уфли эти в\n",
      "уфли эти во всем этих столике и поднялся в какой-то странно поднялся в какой-то странно поднялся в какой-то ст==================================================\n",
      "Итерация #: 22\n",
      "Epoch 1/1\n",
      "752033/752033 [==============================] - 49s 66us/step - loss: 1.4179\n",
      "Генерация из посева: Иудеи, а б\n",
      "Иудеи, а больше не понимаю, что он поднял свою руку и поднялся в сторону и поднялся в сторону и поднялся в сто==================================================\n",
      "Итерация #: 23\n",
      "Epoch 1/1\n",
      "752033/752033 [==============================] - 50s 66us/step - loss: 1.4143\n",
      "Генерация из посева: о в Вологд\n",
      "о в Вологде и поднялся на столе под ним под колоннами, поднялся на столе под ним под колоннами, поднялся на ст==================================================\n",
      "Итерация #: 24\n",
      "Epoch 1/1\n",
      "752033/752033 [==============================] - 49s 65us/step - loss: 1.4122\n",
      "Генерация из посева: ождь, и от\n",
      "ождь, и от этого не пришел в переулок и поднялся в сторону и поднялся в сторону и поднялся в сторону и поднялс\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers.recurrent import SimpleRNN, LSTM, GRU\n",
    "from keras.models import Sequential\n",
    "\n",
    "FILE = \"МастерМаргарита.txt\"\n",
    "\n",
    "# построчное чтение из примера с текстом \n",
    "with open(FILE, 'rb') as _in:\n",
    "    lines = []\n",
    "    for line in _in:\n",
    "        line = line.strip().lower().decode(\"utf8\", \"ignore\")\n",
    "        if len(line) == 0:\n",
    "            continue\n",
    "        lines.append(line)\n",
    "text = \" \".join(lines)\n",
    "chars = set([c for c in text])\n",
    "nb_chars = len(chars)\n",
    "\n",
    "\n",
    "# создание индекса символов и reverse mapping чтобы передвигаться между значениями numerical\n",
    "# ID and a specific character. The numerical ID will correspond to a column\n",
    "# ID и определенный символ. Numerical ID будет соответсвовать колонке\n",
    "# число при использовании one-hot кодировки для представление входов символов\n",
    "char2index = {c: i for i, c in enumerate(chars)}\n",
    "index2char = {i: c for i, c in enumerate(chars)}\n",
    "\n",
    "# для удобства выберете фиксированную длину последовательность 10 символов \n",
    "SEQLEN, STEP = 10, 1\n",
    "input_chars, label_chars = [], []\n",
    "\n",
    "# конвертация data в серии разных SEQLEN-length субпоследовательностей\n",
    "for i in range(0, len(text) - SEQLEN, STEP):\n",
    "    input_chars.append(text[i: i + SEQLEN])\n",
    "    label_chars.append(text[i + SEQLEN])\n",
    "\n",
    "\n",
    "# Вычисление one-hot encoding входных последовательностей X и следующего символа (the label) y\n",
    "\n",
    "X = np.zeros((len(input_chars), SEQLEN, nb_chars), dtype=np.bool)\n",
    "y = np.zeros((len(input_chars), nb_chars), dtype=np.bool)\n",
    "for i, input_char in enumerate(input_chars):\n",
    "    for j, ch in enumerate(input_char):\n",
    "        X[i, j, char2index[ch]] = 1\n",
    "    y[i, char2index[label_chars[i]]] = 1\n",
    "\n",
    "\n",
    "# установка ряда метапамертров  для нейронной сети и процесса тренировки\n",
    "BATCH_SIZE, HIDDEN_SIZE = 256, 256\n",
    "NUM_ITERATIONS = 25 # 25 должно быть достаточно\n",
    "NUM_EPOCHS_PER_ITERATION = 1\n",
    "NUM_PREDS_PER_EPOCH = 100\n",
    "\n",
    "\n",
    "# Create a super simple recurrent neural network. There is one recurrent\n",
    "# layer that produces an embedding of size HIDDEN_SIZE from the one-hot\n",
    "# encoded input layer. This is followed by a Dense fully-connected layer\n",
    "# across the set of possible next characters, which is converted to a\n",
    "# probability score via a standard softmax activation with a multi-class\n",
    "# cross-entropy loss function linking the prediction to the one-hot\n",
    "# encoding character label.\n",
    "\n",
    "'''\n",
    "Создание очень простой рекуррентной нейронной сети. \n",
    "В ней будет один реккурентный закодированный входной слой. \n",
    "За ним последует полносвязный слой связанный с набором возможных следующих символов, которые конвертированы в вероятностные результаты \n",
    "через стандартную softmax активацию с multi-class cross-encoding loss функцию \n",
    "ссылающуются на предсказание one-hot encoding лейбл символа\n",
    "'''\n",
    "\n",
    "model = Sequential()\n",
    "model.add(\n",
    "    GRU(  # вы можете изменить эту часть на LSTM или SimpleRNN, чтобы попробовать альтернативы\n",
    "        HIDDEN_SIZE,\n",
    "        return_sequences=True,\n",
    "        input_shape=(SEQLEN, nb_chars),\n",
    "        unroll=True\n",
    "    )\n",
    ")\n",
    "model.add(LSTM(HIDDEN_SIZE, dropout=0.3, recurrent_dropout=0.2, return_sequences=False)) \n",
    "\n",
    "model.add(Dense(nb_chars))\n",
    "model.add(Activation(\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")\n",
    "\n",
    "\n",
    "# выполнение серий тренировочных и демонстрационных итераций \n",
    "for iteration in range(NUM_ITERATIONS):\n",
    "\n",
    "    # для каждой итерации запуск передачи данных в модель \n",
    "    print(\"=\" * 50)\n",
    "    print(\"Итерация #: %d\" % (iteration))\n",
    "    model.fit(X, y, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS_PER_ITERATION)\n",
    "\n",
    "    # Select a random example input sequence.\n",
    "    test_idx = np.random.randint(len(input_chars))\n",
    "    test_chars = input_chars[test_idx]\n",
    "\n",
    "    # для числа шагов предсказаний использование текущей тренируемой модели \n",
    "    # конструирование one-hot encoding для тестирования input и добавление предсказания.\n",
    "    print(\"Генерация из посева: %s\" % (test_chars))\n",
    "    print(test_chars, end=\"\")\n",
    "    for i in range(NUM_PREDS_PER_EPOCH):\n",
    "\n",
    "        # здесь one-hot encoding.\n",
    "        X_test = np.zeros((1, SEQLEN, nb_chars))\n",
    "        for j, ch in enumerate(test_chars):\n",
    "            X_test[0, j, char2index[ch]] = 1\n",
    "\n",
    "        # осуществление предсказания с помощью текущей модели.\n",
    "        pred = model.predict(X_test, verbose=0)[0]\n",
    "        y_pred = index2char[np.argmax(pred)]\n",
    "\n",
    "        # вывод предсказания добавленного к тестовому примеру \n",
    "        print(y_pred, end=\"\")\n",
    "\n",
    "        # инкрементация тестового примера содержащего предсказание\n",
    "        test_chars = test_chars[1:] + y_pred\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Мои наблюдения за GRU\n",
    "\n",
    "<ol>\n",
    "    <li>Взял в качестве основы Мастер и Марогарита(</li>\n",
    "    <li>Честно говоря не очень понял что на что здесь влияет и как можно что то подкрутить в лучшую сторону (</li>\n",
    "    <li> -\0/-</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
