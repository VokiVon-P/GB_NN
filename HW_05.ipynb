{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Введение в искусственные нейронные сети\n",
    "# Урок 5. Рекуррентные нейронные сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HomeWork 05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте попробуем сделать простую реккурентную нейронную сеть, которая будет учиться складывать числа. Для этих целей мы не будем пользоваться фреймворками для Deep Learning, чтобы посмотреть как она работает внутри.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_stats(hist, score):\n",
    "    plt.plot(hist.history['accuracy'])\n",
    "    plt.plot(hist.history['val_accuracy'])\n",
    "    print(f\"Лучшее кол-во эпох: {np.argmax(hist.history['val_accuracy'])+1} \\\n",
    "          accuracy = {np.max(hist.history['val_accuracy'])}\")\n",
    "#     print(f\"Test accuracy: {score[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь давайте попробуем с помощью Keras построить LSTM нейронную сеть для оценки настроений отзвывов на IMD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данный датасет слишком мал, чтобы преимущества LSTM проявились, однако в учебных целях он подойдет.\n",
    "\n",
    "В тренировке рекуррентных нейронных сетей важную роль играет размер batch, но еще большую роль играет выбор функций loss и optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка данных...\n",
      "25000 тренировочные последовательности\n",
      "25000 тестовые последовательности\n",
      "Pad последовательности (примеров в x единицу времени)\n",
      "x_train shape: (25000, 100)\n",
      "x_test shape: (25000, 100)\n",
      "Построение модели...\n",
      "Процесс обучения...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\_ds_\\_env_\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/5\n",
      "25000/25000 [==============================] - 67s 3ms/step - loss: 0.5583 - accuracy: 0.7138 - val_loss: 0.3745 - val_accuracy: 0.8358\n",
      "Epoch 2/5\n",
      "25000/25000 [==============================] - 70s 3ms/step - loss: 0.3601 - accuracy: 0.8546 - val_loss: 0.3498 - val_accuracy: 0.8463\n",
      "Epoch 3/5\n",
      "25000/25000 [==============================] - 66s 3ms/step - loss: 0.2969 - accuracy: 0.8826 - val_loss: 0.3461 - val_accuracy: 0.8534\n",
      "Epoch 4/5\n",
      "25000/25000 [==============================] - 64s 3ms/step - loss: 0.2534 - accuracy: 0.9034 - val_loss: 0.3603 - val_accuracy: 0.8548\n",
      "Epoch 5/5\n",
      "25000/25000 [==============================] - 65s 3ms/step - loss: 0.2478 - accuracy: 0.9098 - val_loss: 0.3445 - val_accuracy: 0.8550\n",
      "25000/25000 [==============================] - 11s 429us/step\n",
      "Результат при тестировании: 0.34452616280317305\n",
      "Тестовая точность: 0.8550000190734863\n",
      "Wall time: 5min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from __future__ import print_function\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional\n",
    "from keras.layers import LSTM\n",
    "from keras.datasets import imdb\n",
    "from keras import optimizers\n",
    "\n",
    "\n",
    "max_features = 20000\n",
    "\n",
    "# обрезание текстов после данного количества слов (среди top max_features наиболее используемые слова)\n",
    "maxlen = 100\n",
    "batch_size = 100 # увеличьте значение для ускорения обучения\n",
    "num_epoch = 5\n",
    "\n",
    "print('Загрузка данных...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), 'тренировочные последовательности')\n",
    "print(len(x_test), 'тестовые последовательности')\n",
    "\n",
    "print('Pad последовательности (примеров в x единицу времени)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "print('Построение модели...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(256, dropout=0.3, recurrent_dropout=0.2, return_sequences=True))  \n",
    "model.add(LSTM(256, dropout=0.3, recurrent_dropout=0.2, return_sequences=True))  \n",
    "model.add(LSTM(256, dropout=0.3, recurrent_dropout=0.2))\n",
    "\n",
    "model.add(Dense(256, activation='relu', name='FC1'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# стоит попробовать использовать другие оптимайзер и другие конфигурации оптимайзеров \n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='RMSprop',\n",
    "#               optimizer=optimizers.Nadam(learning_rate=0.001),\n",
    "#               optimizer='adamax',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Процесс обучения...')\n",
    "hist = model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=num_epoch, # увеличьте при необходимости\n",
    "          validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Результат при тестировании:', score)\n",
    "print('Тестовая точность:', acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшее кол-во эпох: 5           accuracy = 0.8550000190734863\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_stats(hist, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Мои наблюдения по LSTM\n",
    "\n",
    "<ol>\n",
    "    <li>Увеличение maxlen до 100 помогло увеличить точность</li>\n",
    "    <li>Размер батча повел себя интересно: при простых сетях уменьшение батча увеличивало качество, при усложнении сети батч меньше 100 приводил к ухудшению</li>\n",
    "    <li>Оптимизатор и его параметры не особенно сказались на точности системы (перебрал adam, adamax, RMSprop, Nadam </li>\n",
    "    <li>Добавление стекинга с дополнительными LTSM слоями стабилизировали результаты и немного увеличил точность</li>\n",
    "    <li>Добавление дополнительной комбинации денс слоя с дропаутом позволили обучаться дальше 1 эпохи и также повысили точность </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Часть 2 - генератор GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте также посмотрим пример в котором будет использоваться другой класс задач - генерация текста на основе тренировочного текста. В задачу нейросети будет входить обучившись на тексте Алиса в стране чудес и начать генерировать текст похожий на тот, что можно встретить в этой книге. Также в этом примере будет использоваться GRU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Sub in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Add in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Wall time: 6.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers.recurrent import SimpleRNN, LSTM, GRU\n",
    "from keras.models import Sequential\n",
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "FILE = \"МастерМаргарита.txt\"\n",
    "\n",
    "# построчное чтение из примера с текстом \n",
    "with open(FILE, 'rb') as _in:\n",
    "    lines = []\n",
    "    for line in _in:\n",
    "        line = line.strip().lower().decode(\"utf8\", \"ignore\")\n",
    "        if len(line) == 0:\n",
    "            continue\n",
    "        lines.append(line)\n",
    "text = \" \".join(lines)\n",
    "chars = set([c for c in text])\n",
    "nb_chars = len(chars)\n",
    "\n",
    "\n",
    "# создание индекса символов и reverse mapping чтобы передвигаться между значениями numerical\n",
    "# ID and a specific character. The numerical ID will correspond to a column\n",
    "# ID и определенный символ. Numerical ID будет соответсвовать колонке\n",
    "# число при использовании one-hot кодировки для представление входов символов\n",
    "char2index = {c: i for i, c in enumerate(chars)}\n",
    "index2char = {i: c for i, c in enumerate(chars)}\n",
    "\n",
    "# для удобства выберете фиксированную длину последовательность 10 символов \n",
    "SEQLEN, STEP = 10, 1\n",
    "input_chars, label_chars = [], []\n",
    "\n",
    "# конвертация data в серии разных SEQLEN-length субпоследовательностей\n",
    "for i in range(0, len(text) - SEQLEN, STEP):\n",
    "    input_chars.append(text[i: i + SEQLEN])\n",
    "    label_chars.append(text[i + SEQLEN])\n",
    "\n",
    "\n",
    "# Вычисление one-hot encoding входных последовательностей X и следующего символа (the label) y\n",
    "\n",
    "X = np.zeros((len(input_chars), SEQLEN, nb_chars), dtype=np.bool)\n",
    "y = np.zeros((len(input_chars), nb_chars), dtype=np.bool)\n",
    "for i, input_char in enumerate(input_chars):\n",
    "    for j, ch in enumerate(input_char):\n",
    "        X[i, j, char2index[ch]] = 1\n",
    "    y[i, char2index[label_chars[i]]] = 1\n",
    "\n",
    "\n",
    "# установка ряда метапамертров  для нейронной сети и процесса тренировки\n",
    "BATCH_SIZE, HIDDEN_SIZE = 256, 512\n",
    "NUM_ITERATIONS = 50 # 25 должно быть достаточно\n",
    "NUM_EPOCHS_PER_ITERATION = 2\n",
    "NUM_PREDS_PER_EPOCH = 100\n",
    "\n",
    "\n",
    "# Create a super simple recurrent neural network. There is one recurrent\n",
    "# layer that produces an embedding of size HIDDEN_SIZE from the one-hot\n",
    "# encoded input layer. This is followed by a Dense fully-connected layer\n",
    "# across the set of possible next characters, which is converted to a\n",
    "# probability score via a standard softmax activation with a multi-class\n",
    "# cross-entropy loss function linking the prediction to the one-hot\n",
    "# encoding character label.\n",
    "\n",
    "'''\n",
    "Создание очень простой рекуррентной нейронной сети. \n",
    "В ней будет один реккурентный закодированный входной слой. \n",
    "За ним последует полносвязный слой связанный с набором возможных следующих символов, которые конвертированы в вероятностные результаты \n",
    "через стандартную softmax активацию с multi-class cross-encoding loss функцию \n",
    "ссылающуются на предсказание one-hot encoding лейбл символа\n",
    "'''\n",
    "# strategy = tf.distribute.MirroredStrategy()\n",
    "# with strategy.scope():\n",
    "\n",
    "model = Sequential()\n",
    "model.add(\n",
    "    GRU(  # вы можете изменить эту часть на LSTM или SimpleRNN, чтобы попробовать альтернативы\n",
    "        HIDDEN_SIZE,\n",
    "        return_sequences=False,\n",
    "        input_shape=(SEQLEN, nb_chars),\n",
    "        unroll=True\n",
    "    )\n",
    ")\n",
    "#   model.add(LSTM(HIDDEN_SIZE, dropout=0.3, recurrent_dropout=0.2, return_sequences=False)) \n",
    "model.add(Dense(nb_chars))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Итерация #: 0\n",
      "Epoch 1/2\n",
      "Executing op __inference_keras_scratch_graph_3530 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "752033/752033 [==============================] - 36s 47us/step - loss: 2.1921\n",
      "Epoch 2/2\n",
      "752033/752033 [==============================] - 29s 39us/step - loss: 1.7670\n",
      "Генерация из посева: было стуль\n",
      "было стульExecuting op __inference_keras_scratch_graph_27547 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      " в котором с нем доманного стал совершенно не было стал совершенно не было стал совершенно не было с==================================================\n",
      "Итерация #: 1\n",
      "Epoch 1/2\n",
      "752033/752033 [==============================] - 29s 39us/step - loss: 1.6089\n",
      "Epoch 2/2\n",
      "752033/752033 [==============================] - 29s 39us/step - loss: 1.5135\n",
      "Генерация из посева: еменно быт\n",
      "еменно быть с ним под комнате в свой от столо в кабинет под котором он поднял свой притурельный под котором он==================================================\n",
      "Итерация #: 2\n",
      "Epoch 1/2\n",
      "752033/752033 [==============================] - 29s 39us/step - loss: 1.4446\n",
      "Epoch 2/2\n",
      "752033/752033 [==============================] - 29s 39us/step - loss: 1.3890\n",
      "Генерация из посева: сетителей \n",
      "сетителей комнату возвращения и подокрывался и сказал Воланд, – сказал Воланд, – сказал Воланд, – сказал Волан==================================================\n",
      "Итерация #: 3\n",
      "Epoch 1/2\n",
      "752033/752033 [==============================] - 30s 40us/step - loss: 1.3415\n",
      "Epoch 2/2\n",
      "752033/752033 [==============================] - 29s 39us/step - loss: 1.2983\n",
      "Генерация из посева: осыпались \n",
      "осыпались с нем спросил Иван. – Ну вот и возвращения на себе не совершенно не слушала в сторону, и тот самый с==================================================\n",
      "Итерация #: 4\n",
      "Epoch 1/2\n",
      "752033/752033 [==============================] - 30s 40us/step - loss: 1.2589\n",
      "Epoch 2/2\n",
      "752033/752033 [==============================] - 29s 39us/step - loss: 1.2234\n",
      "Генерация из посева: шее шайку \n",
      "шее шайку с подножий подняться, но не только подняться, но не только подняться, но не только подняться, но не ==================================================\n",
      "Итерация #: 5\n",
      "Epoch 1/2\n",
      "752033/752033 [==============================] - 29s 39us/step - loss: 1.1900\n",
      "Epoch 2/2\n",
      "752033/752033 [==============================] - 30s 40us/step - loss: 1.1604\n",
      "Генерация из посева: менуемый А\n",
      "менуемый Азазелло и в полном одиночество стало быть, стало быть, стало быть, стало быть, стало быть, стало быт==================================================\n",
      "Итерация #: 6\n",
      "Epoch 1/2\n",
      "752033/752033 [==============================] - 29s 39us/step - loss: 1.1323\n",
      "Epoch 2/2\n",
      "752033/752033 [==============================] - 30s 40us/step - loss: 1.1068\n",
      "Генерация из посева: л: – Ай, к\n",
      "л: – Ай, кластая камина была сказан так вереницую вопрос: прощение на полу у подниже к столу и засаленную к ст==================================================\n",
      "Итерация #: 7\n",
      "Epoch 1/2\n",
      "752033/752033 [==============================] - 29s 39us/step - loss: 1.0830\n",
      "Epoch 2/2\n",
      "752033/752033 [==============================] - 29s 39us/step - loss: 1.0609\n",
      "Генерация из посева: казывать к\n",
      "казывать комнате волная сумата под шеет беседою. – То все оказалось на своем мучее покинуть во всех углах. Пок==================================================\n",
      "Итерация #: 8\n",
      "Epoch 1/2\n",
      "752033/752033 [==============================] - 30s 40us/step - loss: 1.0413\n",
      "Epoch 2/2\n",
      "752033/752033 [==============================] - 29s 38us/step - loss: 1.0224 0s - loss: 1.02\n",
      "Генерация из посева: езрадостно\n",
      "езрадостное было поэта прислал смерть между казырастенский с последний раз, как он когда горящими глазами и ст==================================================\n",
      "Итерация #: 9\n",
      "Epoch 1/2\n",
      "752033/752033 [==============================] - 29s 39us/step - loss: 1.0056\n",
      "Epoch 2/2\n",
      "752033/752033 [==============================] - 28s 38us/step - loss: 0.9902\n",
      "Генерация из посева: овой. Супр\n",
      "овой. Супруга его прокуратор не надо вскрикнув, улыбаясь: «А вежьите! – воскликнула Маргарита, – но вы не пони==================================================\n",
      "Итерация #: 10\n",
      "Epoch 1/2\n",
      "752033/752033 [==============================] - 28s 38us/step - loss: 0.9757\n",
      "Epoch 2/2\n",
      "752033/752033 [==============================] - 28s 38us/step - loss: 0.9625\n",
      "Генерация из посева: бавив: – и\n",
      "бавив: – игемон, – продолжал Воланд, – и он стараясь не причинила не стола поднимать разрушал его в колонне то==================================================\n",
      "Итерация #: 11\n",
      "Epoch 1/2\n",
      "752033/752033 [==============================] - 28s 38us/step - loss: 0.9501\n",
      "Epoch 2/2\n",
      "752033/752033 [==============================] - 29s 38us/step - loss: 0.9380\n",
      "Генерация из посева: окуратор, \n",
      "окуратор, – ответил Воланд, – что же это такое? – спросил Пилат, – все в порядке что-то произойдет в кабинете ==================================================\n",
      "Итерация #: 12\n",
      "Epoch 1/2\n",
      "752033/752033 [==============================] - 29s 38us/step - loss: 0.9266\n",
      "Epoch 2/2\n",
      "752033/752033 [==============================] - 29s 39us/step - loss: 0.9166\n",
      "Генерация из посева: ршенно ост\n",
      "ршенно оставили с него заговорил Пилат, – телеграммы, всегда обратился к нему и спросила Маргарита стала уходи==================================================\n",
      "Итерация #: 13\n",
      "Epoch 1/2\n",
      "752033/752033 [==============================] - 28s 38us/step - loss: 0.9069\n",
      "Epoch 2/2\n",
      "752033/752033 [==============================] - 29s 38us/step - loss: 0.8978\n",
      "Генерация из посева: рные птицы\n",
      "рные птицы, очень умело. Ведно спросил Иван. – Ну, конечно, не подозревающих молодой человек в капюшоне вскочи==================================================\n",
      "Итерация #: 14\n",
      "Epoch 1/2\n",
      "752033/752033 [==============================] - 29s 39us/step - loss: 0.8891\n",
      "Epoch 2/2\n",
      "752033/752033 [==============================] - 29s 39us/step - loss: 0.8809\n",
      "Генерация из посева: нные, во в\n",
      "нные, во время как следует отчаяния, от нее на Москве. изазали вас спросить, – ответил Азазелло, – ответил Аза==================================================\n",
      "Итерация #: 15\n",
      "Epoch 1/2\n",
      "752033/752033 [==============================] - 29s 38us/step - loss: 0.8734\n",
      "Epoch 2/2\n",
      "752033/752033 [==============================] - 29s 39us/step - loss: 0.8647 0s \n",
      "Генерация из посева: а побелка.\n",
      "а побелка. С котарона на площадки и что на балконе в какой-то девицей предларясь от должность и не повернули г==================================================\n",
      "Итерация #: 16\n",
      "Epoch 1/2\n",
      "752033/752033 [==============================] - 29s 39us/step - loss: 0.8578\n",
      "Epoch 2/2\n",
      "752033/752033 [==============================] - 29s 39us/step - loss: 0.8509\n",
      "Генерация из посева: очему же в\n",
      "очему же вы сердитесь? – Знаю, – ответил Воланд, – не произошло совсем не выражилась на прощание показывали дв==================================================\n",
      "Итерация #: 17\n",
      "Epoch 1/2\n",
      "752033/752033 [==============================] - 29s 39us/step - loss: 0.8448\n",
      "Epoch 2/2\n",
      "752033/752033 [==============================] - 29s 39us/step - loss: 0.8392\n",
      "Генерация из посева:  и надел к\n",
      " и надел кот возевазивались к вошедшим в открытые окна. Москва под ним с половой он сперва больше не приходила==================================================\n",
      "Итерация #: 18\n",
      "Epoch 1/2\n",
      "752033/752033 [==============================] - 29s 39us/step - loss: 0.8329\n",
      "Epoch 2/2\n",
      "752033/752033 [==============================] - 29s 39us/step - loss: 0.8281\n",
      "Генерация из посева: о же, что \n",
      "о же, что не понимаю, какое он когда-либо кивать двой оцепление не может не помнил, что он повернулся к своей ==================================================\n",
      "Итерация #: 19\n",
      "Epoch 1/2\n",
      "752033/752033 [==============================] - 30s 39us/step - loss: 0.8218\n",
      "Epoch 2/2\n",
      "752033/752033 [==============================] - 31s 41us/step - loss: 0.8170\n",
      "Генерация из посева: ли ж вам н\n",
      "ли ж вам не пришел потолковать о том, что в театральной и физдировкнела ись, и с камнями и фальшивыми касным г==================================================\n",
      "Итерация #: 20\n",
      "Epoch 1/2\n",
      "752033/752033 [==============================] - 30s 40us/step - loss: 0.8133\n",
      "Epoch 2/2\n",
      "752033/752033 [==============================] - 30s 40us/step - loss: 0.8077\n",
      "Генерация из посева: ану на мос\n",
      "ану на моств подумать о том, что он повернулся и пошел по самой сходной вообще в подставленной квартиры, в кот==================================================\n",
      "Итерация #: 21\n",
      "Epoch 1/2\n",
      "752033/752033 [==============================] - 29s 39us/step - loss: 0.8038\n",
      "Epoch 2/2\n",
      "752033/752033 [==============================] - 30s 39us/step - loss: 0.7993\n",
      "Генерация из посева: орода в го\n",
      "орода в город, серьезабро, увидела колено Маргариты Николаевна оставила на улицу и привел слов, – как вам буде==================================================\n",
      "Итерация #: 22\n",
      "Epoch 1/2\n",
      "752033/752033 [==============================] - 30s 40us/step - loss: 0.7951\n",
      "Epoch 2/2\n",
      "752033/752033 [==============================] - 29s 39us/step - loss: 0.7903\n",
      "Генерация из посева:  испуганно\n",
      " испуганно поглядел на нее в этом же роде. Вы все знали, что она не пришлось спросить вас к себе на пол. Но по==================================================\n",
      "Итерация #: 23\n",
      "Epoch 1/2\n",
      "752033/752033 [==============================] - 29s 39us/step - loss: 0.7862\n",
      "Epoch 2/2\n",
      "752033/752033 [==============================] - 29s 39us/step - loss: 0.7825\n",
      "Генерация из посева: рокричала \n",
      "рокричала супрагу кентурии на пол. Под великорой поманили в саду: – Преступнендав то же слоукива и возволящие ==================================================\n",
      "Итерация #: 24\n",
      "Epoch 1/2\n",
      "752033/752033 [==============================] - 30s 40us/step - loss: 0.7789\n",
      "Epoch 2/2\n",
      "752033/752033 [==============================] - 30s 39us/step - loss: 0.7750\n",
      "Генерация из посева: еть – хала\n",
      "еть – халатикого соедиников, по которой сидел в трамвай, а потом по труб аму, а позвонила в грудь, он подвижен==================================================\n",
      "Итерация #: 25\n",
      "Epoch 1/2\n",
      "752033/752033 [==============================] - 29s 39us/step - loss: 0.7725\n",
      "Epoch 2/2\n",
      "752033/752033 [==============================] - ETA: 0s - loss: 0.767 - 29s 39us/step - loss: 0.7672\n",
      "Генерация из посева: ем времене\n",
      "ем временем сейчас же стоял гость. – Не сомневайся, молодые сюрари, но ничего не слыхал! – вовые не было ни св==================================================\n",
      "Итерация #: 26\n",
      "Epoch 1/2\n",
      "752033/752033 [==============================] - 29s 39us/step - loss: 0.7651\n",
      "Epoch 2/2\n",
      "752033/752033 [==============================] - 29s 39us/step - loss: 0.7617\n",
      "Генерация из посева: дписанная \n",
      "дписанная буква на верную пальцом, продолжал посетителями в руках портфель, но и не мог проньки вылисы сделала==================================================\n",
      "Итерация #: 27\n",
      "Epoch 1/2\n",
      "752033/752033 [==============================] - 29s 39us/step - loss: 0.7602\n",
      "Epoch 2/2\n",
      "752033/752033 [==============================] - 29s 39us/step - loss: 0.7568\n",
      "Генерация из посева:  кого сейч\n",
      " кого сейчас же подхватил Коровьев, – и тут он поднял свет оттуда. Коровьев и Бегемот посторонились в том, что==================================================\n",
      "Итерация #: 28\n",
      "Epoch 1/2\n",
      "752033/752033 [==============================] - 29s 39us/step - loss: 0.7535\n",
      "Epoch 2/2\n",
      "752033/752033 [==============================] - 29s 39us/step - loss: 0.7507\n",
      "Генерация из посева: остаться з\n",
      "остаться здесь. – т конечно, не понимал, что пришеле на пол. В залавое огляделась на повторился эти глаза коро==================================================\n",
      "Итерация #: 29\n",
      "Epoch 1/2\n",
      "752033/752033 [==============================] - 29s 39us/step - loss: 0.7484\n",
      "Epoch 2/2\n",
      "752033/752033 [==============================] - 29s 39us/step - loss: 0.7457 0\n",
      "Генерация из посева: ажи, – тут\n",
      "ажи, – тут прокуратор подумал: «А тебя были убедиться нечего были понятны, так сказать, что он просит отпустит==================================================\n",
      "Итерация #: 30\n",
      "Epoch 1/2\n",
      "752033/752033 [==============================] - 29s 39us/step - loss: 0.7430\n",
      "Epoch 2/2\n",
      "752033/752033 [==============================] - 29s 39us/step - loss: 0.7398\n",
      "Генерация из посева: е повязке,\n",
      "е повязке, но не сумотоски покрыв я тель Иешуа. В первый копытцы, и не смолкнет на прощанье показать совершенн==================================================\n",
      "Итерация #: 31\n",
      "Epoch 1/2\n",
      "752033/752033 [==============================] - 29s 38us/step - loss: 0.7386\n",
      "Epoch 2/2\n",
      "752033/752033 [==============================] - 29s 38us/step - loss: 0.7351\n",
      "Генерация из посева: . Нарыдавш\n",
      ". Нарыдавшись второе вороб и с замешать, – ответил Азазелло и выходил на каменном стале ни в каких произнести ==================================================\n",
      "Итерация #: 32\n",
      "Epoch 1/2\n",
      "752033/752033 [==============================] - 31s 41us/step - loss: 0.7318\n",
      "Epoch 2/2\n",
      "752033/752033 [==============================] - 29s 39us/step - loss: 0.7310\n",
      "Генерация из посева:  – Куда же\n",
      " – Куда же ты и с едищихующему прость покойному Берлиозу она, совсем уже не знали знаменитый писатель поставит==================================================\n",
      "Итерация #: 33\n",
      "Epoch 1/2\n",
      "752033/752033 [==============================] - 30s 39us/step - loss: 0.7290\n",
      "Epoch 2/2\n",
      "752033/752033 [==============================] - 31s 41us/step - loss: 0.7258\n",
      "Генерация из посева: о, как по \n",
      "о, как по лестнице, выдеритей, которые он не может быть, и все подумал: «А теперь уже ваши времени примасно сл==================================================\n",
      "Итерация #: 34\n",
      "Epoch 1/2\n",
      "752033/752033 [==============================] - 30s 40us/step - loss: 0.7238\n",
      "Epoch 2/2\n",
      "752033/752033 [==============================] - 29s 39us/step - loss: 0.7231\n",
      "Генерация из посева: нь рада. Л\n",
      "нь рада. Любите ли вы навели их повернули ее проговорил повернул в ободго переждившиеся сомнения, были в сапог==================================================\n",
      "Итерация #: 35\n",
      "Epoch 1/2\n",
      "752033/752033 [==============================] - 30s 40us/step - loss: 0.7197\n",
      "Epoch 2/2\n",
      "752033/752033 [==============================] - 30s 40us/step - loss: 0.7179\n",
      "Генерация из посева: уматься. П\n",
      "уматься. Поэтому нет ничего не было, кроме одного из своих чаши. Вслусшись своего собеседника. Обычно мастера ==================================================\n",
      "Итерация #: 36\n",
      "Epoch 1/2\n",
      "752033/752033 [==============================] - 29s 39us/step - loss: 0.7172\n",
      "Epoch 2/2\n",
      "752033/752033 [==============================] - 29s 39us/step - loss: 0.7146\n",
      "Генерация из посева: , было сов\n",
      ", было совершенно не пожимого недопротивников как бы заставила его мне на это, негодая, уже не собирался произ==================================================\n",
      "Итерация #: 37\n",
      "Epoch 1/2\n",
      "752033/752033 [==============================] - 30s 39us/step - loss: 0.7127\n",
      "Epoch 2/2\n",
      "752033/752033 [==============================] - 30s 39us/step - loss: 0.7111\n",
      "Генерация из посева: лу, к делу\n",
      "лу, к делу, отозвался кот и так же подхватил на свое место, в одном белье, но подошел к перзому попала в переу==================================================\n",
      "Итерация #: 38\n",
      "Epoch 1/2\n",
      "752033/752033 [==============================] - 30s 39us/step - loss: 0.7087\n",
      "Epoch 2/2\n",
      "752033/752033 [==============================] - 30s 40us/step - loss: 0.7071\n",
      "Генерация из посева: Маргарита,\n",
      "Маргарита, – что ваша теория и сказал: – Ответить мастер и поднялся, – но тресствой в женщину в подвал. – Не в==================================================\n",
      "Итерация #: 39\n",
      "Epoch 1/2\n",
      "752033/752033 [==============================] - 31s 42us/step - loss: 0.7058\n",
      "Epoch 2/2\n",
      "752033/752033 [==============================] - 31s 41us/step - loss: 0.7032\n",
      "Генерация из посева: о тротуара\n",
      "о тротуарами, столо заплакать, с сообщение о том, что он подумал и пригласил по телефону в подвале и пошел по ==================================================\n",
      "Итерация #: 40\n",
      "Epoch 1/2\n",
      "752033/752033 [==============================] - 31s 41us/step - loss: 0.7008\n",
      "Epoch 2/2\n",
      "752033/752033 [==============================] - 30s 39us/step - loss: 0.7014\n",
      "Генерация из посева: тельно сли\n",
      "тельно слишком много приговора на площадке с этого говоря, сжигаемой этой рукой, а глаза Маргарита на левую са==================================================\n",
      "Итерация #: 41\n",
      "Epoch 1/2\n",
      "752033/752033 [==============================] - 29s 39us/step - loss: 0.6983\n",
      "Epoch 2/2\n",
      "752033/752033 [==============================] - 30s 39us/step - loss: 0.6970\n",
      "Генерация из посева: молнию. Ва\n",
      "молнию. Варьете у вас видел этого мага не было слышно. – Ну, стольными зразеломомлоску в долг . Ведши лун иот ==================================================\n",
      "Итерация #: 42\n",
      "Epoch 1/2\n",
      "752033/752033 [==============================] - 29s 39us/step - loss: 0.6957\n",
      "Epoch 2/2\n",
      "752033/752033 [==============================] - 30s 40us/step - loss: 0.6931\n",
      "Генерация из посева: ина: – Жен\n",
      "ина: – Женат обещает какой-то страшно прокричал сильнее веселел. Но там поглядел в подвалом освещением надежда==================================================\n",
      "Итерация #: 43\n",
      "Epoch 1/2\n",
      "752033/752033 [==============================] - 30s 39us/step - loss: 0.6924\n",
      "Epoch 2/2\n",
      "752033/752033 [==============================] - 30s 39us/step - loss: 0.6903\n",
      "Генерация из посева: , – подума\n",
      ", – подумал неовидны? – вкридочному обидюние. Она полагто. Но себя Маловраареранную голову будать обродника по==================================================\n",
      "Итерация #: 44\n",
      "Epoch 1/2\n",
      "752033/752033 [==============================] - 29s 39us/step - loss: 0.6889\n",
      "Epoch 2/2\n",
      "752033/752033 [==============================] - 29s 38us/step - loss: 0.6892\n",
      "Генерация из посева: ора, продо\n",
      "ора, продолжал Воланд, – он не вопросительный взор к Воланду, вступил на мастера и заглянул в подъезд, и в сто==================================================\n",
      "Итерация #: 45\n",
      "Epoch 1/2\n",
      "752033/752033 [==============================] - 29s 39us/step - loss: 0.6867\n",
      "Epoch 2/2\n",
      "752033/752033 [==============================] - 29s 38us/step - loss: 0.6850\n",
      "Генерация из посева: вшись спро\n",
      "вшись спросил Иван. – Я знаю, – ответил Иван уже не понимая, как это миного в мире, – так как на недну, как и ==================================================\n",
      "Итерация #: 46\n",
      "Epoch 1/2\n",
      "752033/752033 [==============================] - 29s 38us/step - loss: 0.6837\n",
      "Epoch 2/2\n",
      "752033/752033 [==============================] - 29s 38us/step - loss: 0.6833\n",
      "Генерация из посева: ита задумч\n",
      "ита задумчиво ответил Афраний, – о вышеплена улитьясь, проникнуть в его статьица, только от подной красной жид==================================================\n",
      "Итерация #: 47\n",
      "Epoch 1/2\n",
      "752033/752033 [==============================] - 29s 38us/step - loss: 0.6812\n",
      "Epoch 2/2\n",
      "752033/752033 [==============================] - 29s 39us/step - loss: 0.6798\n",
      "Генерация из посева: ного бока \n",
      "ного бока солнцем глобус. Носколько раз мог же не вовсе ты инименно телефон. – Да! – послышался горяч, у котор==================================================\n",
      "Итерация #: 48\n",
      "Epoch 1/2\n",
      "752033/752033 [==============================] - 29s 38us/step - loss: 0.6794\n",
      "Epoch 2/2\n",
      "752033/752033 [==============================] - 29s 38us/step - loss: 0.6761\n",
      "Генерация из посева: мычал. Про\n",
      "мычал. Продавтой как раз в то время как оба обеданая и она повалилась прямо на стекло часов, от чего оно сдела==================================================\n",
      "Итерация #: 49\n",
      "Epoch 1/2\n",
      "752033/752033 [==============================] - 29s 38us/step - loss: 0.6759\n",
      "Epoch 2/2\n",
      "752033/752033 [==============================] - 29s 38us/step - loss: 0.6746\n",
      "Генерация из посева: ушел после\n",
      "ушел последний вопрос. – Во что, смотря, – задарал глаза на арестанта, и в этот же мантере в спину, рьмая вась\n"
     ]
    }
   ],
   "source": [
    "# выполнение серий тренировочных и демонстрационных итераций \n",
    "\n",
    "for iteration in range(NUM_ITERATIONS):\n",
    "\n",
    "    # для каждой итерации запуск передачи данных в модель \n",
    "    print(\"=\" * 50)\n",
    "    print(\"Итерация #: %d\" % (iteration))\n",
    "    model.fit(X, y, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS_PER_ITERATION)\n",
    "\n",
    "    # Select a random example input sequence.\n",
    "    test_idx = np.random.randint(len(input_chars))\n",
    "    test_chars = input_chars[test_idx]\n",
    "\n",
    "    # для числа шагов предсказаний использование текущей тренируемой модели \n",
    "    # конструирование one-hot encoding для тестирования input и добавление предсказания.\n",
    "    print(\"Генерация из посева: %s\" % (test_chars))\n",
    "    print(test_chars, end=\"\")\n",
    "    for i in range(NUM_PREDS_PER_EPOCH):\n",
    "\n",
    "        # здесь one-hot encoding.\n",
    "        X_test = np.zeros((1, SEQLEN, nb_chars))\n",
    "        for j, ch in enumerate(test_chars):\n",
    "            X_test[0, j, char2index[ch]] = 1\n",
    "\n",
    "        # осуществление предсказания с помощью текущей модели.\n",
    "        pred = model.predict(X_test, verbose=0)[0]\n",
    "        y_pred = index2char[np.argmax(pred)]\n",
    "\n",
    "        # вывод предсказания добавленного к тестовому примеру \n",
    "        print(y_pred, end=\"\")\n",
    "\n",
    "        # инкрементация тестового примера содержащего предсказание\n",
    "        test_chars = test_chars[1:] + y_pred\n",
    "        \n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Мои наблюдения за GRU\n",
    "\n",
    "<ol>\n",
    "    <li>Уже что то получилось</li>\n",
    "    <li>Закономерность я пока для себя не вывел - но уже есть с чем работать</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
